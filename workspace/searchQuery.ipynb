{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Fungsi untuk melakukan pencarian artikel dan mengambil konten dari Wikipedia API Bahasa Indonesia\n",
    "def search_wikipedia_indonesian(query):\n",
    "    search_url = \"https://id.wikipedia.org/w/api.php\"\n",
    "    search_params = {\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"search\",\n",
    "        \"srsearch\": query,\n",
    "        \"format\": \"json\",\n",
    "        \"utf8\": 1,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Pencarian artikel berdasarkan kata kunci\n",
    "        search_response = requests.get(search_url, params=search_params)\n",
    "        if search_response.status_code == 200:\n",
    "            search_data = search_response.json()\n",
    "            search_results = search_data.get(\"query\", {}).get(\"search\", [])\n",
    "            \n",
    "            if not search_results:\n",
    "                return \"Tidak ada hasil yang ditemukan.\", []\n",
    "\n",
    "            # Mengambil pageid dari hasil pencarian pertama\n",
    "            page_id = search_results[0][\"pageid\"]\n",
    "            extract_url = \"https://id.wikipedia.org/w/api.php\"\n",
    "            extract_params = {\n",
    "                \"action\": \"query\",\n",
    "                \"pageids\": page_id,\n",
    "                \"prop\": \"extracts\",\n",
    "                \"explaintext\": 1,\n",
    "                \"format\": \"json\",\n",
    "            }\n",
    "\n",
    "            # Mengambil konten artikel berdasarkan pageid\n",
    "            extract_response = requests.get(extract_url, params=extract_params)\n",
    "            if extract_response.status_code == 200:\n",
    "                extract_data = extract_response.json()\n",
    "                page = extract_data.get(\"query\", {}).get(\"pages\", {}).get(str(page_id), {})\n",
    "                title = page.get(\"title\", \"Tidak ada judul\")\n",
    "                extract = page.get(\"extract\", \"Tidak ada konten yang ditemukan.\")\n",
    "                return title, extract\n",
    "            else:\n",
    "                return f\"Error: HTTP Status {extract_response.status_code}\", []\n",
    "        else:\n",
    "            return f\"Error: HTTP Status {search_response.status_code}\", []\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", []\n",
    "\n",
    "# Daftar query terkait kesehatan mental dalam Bahasa Indonesia\n",
    "queries = [\n",
    "    \"stress akut apa yang perlu saya lakukan\",\n",
    "]\n",
    "\n",
    "# Menguji query-query tersebut dan menampilkan hasilnya\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    title, content = search_wikipedia_indonesian(query)\n",
    "\n",
    "    if isinstance(title, str) and isinstance(content, str):\n",
    "        print(f\"Judul: {title}\\nKonten:\\n{content}\\n\")\n",
    "    else:\n",
    "        print(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teks Asli: Apa itu terapi kognitif perilaku?\n",
      "Terjemahan: What is behavioral cognitive therapy?\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "# Fungsi untuk menerjemahkan teks menggunakan googletrans\n",
    "def translate_text_google(text, source_lang=\"id\", target_lang=\"en\"):\n",
    "    translator = Translator()\n",
    "    try:\n",
    "        translation = translator.translate(text, src=source_lang, dest=target_lang)\n",
    "        return translation.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Contoh penggunaan\n",
    "text = \"Apa itu terapi kognitif perilaku?\"\n",
    "translated_text = translate_text_google(text)\n",
    "print(f\"Teks Asli: {text}\\nTerjemahan: {translated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model path does not exist: asset/llama-2-7b-chat.ggmlv3.q8_0.bin",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masset/llama-2-7b-chat.ggmlv3.q8_0.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Memuat model tanpa training, hanya untuk inferensi\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mLlama\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Fungsi untuk menghasilkan respons dari model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat_with_llama\u001b[39m(user_input):\n",
      "File \u001b[0;32m/media/debian/OS/Code/Machine Learning - Workspace/Competition/TSDN-2024/venv/lib/python3.11/site-packages/llama_cpp/llama.py:365\u001b[0m, in \u001b[0;36mLlama.__init__\u001b[0;34m(self, model_path, n_gpu_layers, split_mode, main_gpu, tensor_split, rpc_servers, vocab_only, use_mmap, use_mlock, kv_overrides, seed, n_ctx, n_batch, n_ubatch, n_threads, n_threads_batch, rope_scaling_type, pooling_type, rope_freq_base, rope_freq_scale, yarn_ext_factor, yarn_attn_factor, yarn_beta_fast, yarn_beta_slow, yarn_orig_ctx, logits_all, embedding, offload_kqv, flash_attn, last_n_tokens_size, lora_base, lora_scale, lora_path, numa, chat_format, chat_handler, draft_model, tokenizer, type_k, type_v, spm_infill, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspm_infill \u001b[38;5;241m=\u001b[39m spm_infill\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path):\n\u001b[0;32m--> 365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel path does not exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m    368\u001b[0m     contextlib\u001b[38;5;241m.\u001b[39mclosing(\n\u001b[1;32m    369\u001b[0m         internals\u001b[38;5;241m.\u001b[39mLlamaModel(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m     )\n\u001b[1;32m    375\u001b[0m )\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# Override tokenizer\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Model path does not exist: asset/llama-2-7b-chat.ggmlv3.q8_0.bin"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Path ke model GGML lokal\n",
    "model_path = \"asset/llama-2-7b-chat.ggmlv3.q8_0.bin\"\n",
    "\n",
    "# Memuat model tanpa training, hanya untuk inferensi\n",
    "llm = Llama(model_path=model_path)\n",
    "\n",
    "# Fungsi untuk menghasilkan respons dari model\n",
    "def chat_with_llama(user_input):\n",
    "    prompt = f\"Pertanyaan: {user_input}\\nJawaban:\"\n",
    "    response = llm(prompt, max_tokens=100)\n",
    "    return response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "# Contoh input pengguna\n",
    "user_input = \"Apa yang bisa saya lakukan untuk mengurangi stres?\"\n",
    "print(\"\\nUser Input:\", user_input)\n",
    "\n",
    "# Menghasilkan respons\n",
    "output = chat_with_llama(user_input)\n",
    "print(\"\\nOutput:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3.11 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.3.1.tar.gz (63.9 MB)\n",
      "     ---------------------------------------- 0.0/63.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/63.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/63.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/63.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/63.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.3/63.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.3/63.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.3/63.9 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.5/63.9 MB 409.0 kB/s eta 0:02:35\n",
      "     --------------------------------------- 0.5/63.9 MB 409.0 kB/s eta 0:02:35\n",
      "     --------------------------------------- 0.5/63.9 MB 409.0 kB/s eta 0:02:35\n",
      "     --------------------------------------- 0.8/63.9 MB 430.1 kB/s eta 0:02:27\n",
      "      -------------------------------------- 1.0/63.9 MB 493.4 kB/s eta 0:02:08\n",
      "      -------------------------------------- 1.0/63.9 MB 493.4 kB/s eta 0:02:08\n",
      "      -------------------------------------- 1.3/63.9 MB 528.5 kB/s eta 0:01:59\n",
      "      -------------------------------------- 1.3/63.9 MB 528.5 kB/s eta 0:01:59\n",
      "      -------------------------------------- 1.3/63.9 MB 528.5 kB/s eta 0:01:59\n",
      "      -------------------------------------- 1.6/63.9 MB 505.3 kB/s eta 0:02:04\n",
      "      -------------------------------------- 1.6/63.9 MB 505.3 kB/s eta 0:02:04\n",
      "     - ------------------------------------- 1.8/63.9 MB 513.7 kB/s eta 0:02:01\n",
      "     - ------------------------------------- 1.8/63.9 MB 513.7 kB/s eta 0:02:01\n",
      "     - ------------------------------------- 1.8/63.9 MB 513.7 kB/s eta 0:02:01\n",
      "     - ------------------------------------- 2.1/63.9 MB 521.9 kB/s eta 0:01:59\n",
      "     - ------------------------------------- 2.4/63.9 MB 539.0 kB/s eta 0:01:55\n",
      "     - ------------------------------------- 2.4/63.9 MB 539.0 kB/s eta 0:01:55\n",
      "     - ------------------------------------- 2.6/63.9 MB 561.3 kB/s eta 0:01:50\n",
      "     - ------------------------------------- 2.9/63.9 MB 586.6 kB/s eta 0:01:45\n",
      "     - ------------------------------------- 3.1/63.9 MB 611.1 kB/s eta 0:01:40\n",
      "     - ------------------------------------- 3.1/63.9 MB 611.1 kB/s eta 0:01:40\n",
      "     -- ------------------------------------ 3.4/63.9 MB 629.1 kB/s eta 0:01:37\n",
      "     -- ------------------------------------ 3.7/63.9 MB 649.1 kB/s eta 0:01:33\n",
      "     -- ------------------------------------ 3.9/63.9 MB 667.3 kB/s eta 0:01:30\n",
      "     -- ------------------------------------ 4.2/63.9 MB 685.8 kB/s eta 0:01:28\n",
      "     -- ------------------------------------ 4.2/63.9 MB 685.8 kB/s eta 0:01:28\n",
      "     -- ------------------------------------ 4.5/63.9 MB 695.5 kB/s eta 0:01:26\n",
      "     -- ------------------------------------ 4.7/63.9 MB 706.0 kB/s eta 0:01:24\n",
      "     --- ----------------------------------- 5.0/63.9 MB 724.2 kB/s eta 0:01:22\n",
      "     --- ----------------------------------- 5.2/63.9 MB 734.5 kB/s eta 0:01:20\n",
      "     --- ----------------------------------- 5.2/63.9 MB 734.5 kB/s eta 0:01:20\n",
      "     --- ----------------------------------- 5.5/63.9 MB 744.0 kB/s eta 0:01:19\n",
      "     --- ----------------------------------- 6.0/63.9 MB 773.8 kB/s eta 0:01:15\n",
      "     --- ----------------------------------- 6.3/63.9 MB 787.5 kB/s eta 0:01:14\n",
      "     --- ----------------------------------- 6.6/63.9 MB 802.1 kB/s eta 0:01:12\n",
      "     ---- ---------------------------------- 6.8/63.9 MB 811.3 kB/s eta 0:01:11\n",
      "     ---- ---------------------------------- 7.1/63.9 MB 826.1 kB/s eta 0:01:09\n",
      "     ---- ---------------------------------- 7.3/63.9 MB 837.3 kB/s eta 0:01:08\n",
      "     ---- ---------------------------------- 7.6/63.9 MB 851.0 kB/s eta 0:01:07\n",
      "     ---- ---------------------------------- 7.9/63.9 MB 858.1 kB/s eta 0:01:06\n",
      "     ---- ---------------------------------- 8.1/63.9 MB 864.8 kB/s eta 0:01:05\n",
      "     ----- --------------------------------- 8.7/63.9 MB 896.3 kB/s eta 0:01:02\n",
      "     ----- --------------------------------- 8.9/63.9 MB 906.1 kB/s eta 0:01:01\n",
      "     ----- --------------------------------- 9.2/63.9 MB 923.0 kB/s eta 0:01:00\n",
      "     ----- --------------------------------- 9.4/63.9 MB 933.6 kB/s eta 0:00:59\n",
      "     ----- --------------------------------- 9.7/63.9 MB 943.7 kB/s eta 0:00:58\n",
      "     ------ ------------------------------- 10.2/63.9 MB 960.1 kB/s eta 0:00:56\n",
      "     ------ ------------------------------- 10.7/63.9 MB 989.8 kB/s eta 0:00:54\n",
      "     ------ --------------------------------- 11.0/63.9 MB 1.0 MB/s eta 0:00:53\n",
      "     ------- -------------------------------- 11.5/63.9 MB 1.0 MB/s eta 0:00:51\n",
      "     ------- -------------------------------- 12.1/63.9 MB 1.1 MB/s eta 0:00:50\n",
      "     ------- -------------------------------- 12.6/63.9 MB 1.1 MB/s eta 0:00:48\n",
      "     -------- ------------------------------- 13.4/63.9 MB 1.1 MB/s eta 0:00:45\n",
      "     -------- ------------------------------- 13.9/63.9 MB 1.2 MB/s eta 0:00:44\n",
      "     --------- ------------------------------ 14.7/63.9 MB 1.2 MB/s eta 0:00:42\n",
      "     --------- ------------------------------ 15.2/63.9 MB 1.2 MB/s eta 0:00:40\n",
      "     ---------- ----------------------------- 16.3/63.9 MB 1.3 MB/s eta 0:00:38\n",
      "     ---------- ----------------------------- 16.8/63.9 MB 1.3 MB/s eta 0:00:36\n",
      "     ---------- ----------------------------- 17.6/63.9 MB 1.3 MB/s eta 0:00:35\n",
      "     ----------- ---------------------------- 18.4/63.9 MB 1.4 MB/s eta 0:00:34\n",
      "     ----------- ---------------------------- 18.9/63.9 MB 1.4 MB/s eta 0:00:33\n",
      "     ------------ --------------------------- 19.4/63.9 MB 1.4 MB/s eta 0:00:32\n",
      "     ------------ --------------------------- 19.9/63.9 MB 1.4 MB/s eta 0:00:31\n",
      "     ------------ --------------------------- 20.7/63.9 MB 1.5 MB/s eta 0:00:30\n",
      "     ------------- -------------------------- 21.5/63.9 MB 1.5 MB/s eta 0:00:29\n",
      "     ------------- -------------------------- 22.0/63.9 MB 1.5 MB/s eta 0:00:28\n",
      "     -------------- ------------------------- 22.5/63.9 MB 1.5 MB/s eta 0:00:27\n",
      "     -------------- ------------------------- 23.3/63.9 MB 1.6 MB/s eta 0:00:27\n",
      "     -------------- ------------------------- 23.9/63.9 MB 1.6 MB/s eta 0:00:26\n",
      "     --------------- ------------------------ 24.4/63.9 MB 1.6 MB/s eta 0:00:25\n",
      "     --------------- ------------------------ 24.6/63.9 MB 1.6 MB/s eta 0:00:25\n",
      "     --------------- ------------------------ 25.2/63.9 MB 1.6 MB/s eta 0:00:25\n",
      "     ---------------- ----------------------- 26.0/63.9 MB 1.6 MB/s eta 0:00:24\n",
      "     ---------------- ----------------------- 26.5/63.9 MB 1.6 MB/s eta 0:00:23\n",
      "     ---------------- ----------------------- 27.0/63.9 MB 1.7 MB/s eta 0:00:23\n",
      "     ----------------- ---------------------- 27.8/63.9 MB 1.7 MB/s eta 0:00:22\n",
      "     ----------------- ---------------------- 28.3/63.9 MB 1.7 MB/s eta 0:00:22\n",
      "     ------------------ --------------------- 28.8/63.9 MB 1.7 MB/s eta 0:00:21\n",
      "     ------------------ --------------------- 29.4/63.9 MB 1.7 MB/s eta 0:00:21\n",
      "     ------------------ --------------------- 29.9/63.9 MB 1.7 MB/s eta 0:00:20\n",
      "     ------------------- -------------------- 30.4/63.9 MB 1.7 MB/s eta 0:00:20\n",
      "     ------------------- -------------------- 31.2/63.9 MB 1.8 MB/s eta 0:00:19\n",
      "     -------------------- ------------------- 32.0/63.9 MB 1.8 MB/s eta 0:00:19\n",
      "     -------------------- ------------------- 32.5/63.9 MB 1.8 MB/s eta 0:00:18\n",
      "     -------------------- ------------------- 33.3/63.9 MB 1.8 MB/s eta 0:00:18\n",
      "     --------------------- ------------------ 33.8/63.9 MB 1.8 MB/s eta 0:00:17\n",
      "     --------------------- ------------------ 34.6/63.9 MB 1.8 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 35.4/63.9 MB 1.9 MB/s eta 0:00:16\n",
      "     ---------------------- ----------------- 36.2/63.9 MB 1.9 MB/s eta 0:00:15\n",
      "     ---------------------- ----------------- 36.7/63.9 MB 1.9 MB/s eta 0:00:15\n",
      "     ----------------------- ---------------- 37.5/63.9 MB 1.9 MB/s eta 0:00:14\n",
      "     ----------------------- ---------------- 38.3/63.9 MB 1.9 MB/s eta 0:00:14\n",
      "     ------------------------ --------------- 38.8/63.9 MB 1.9 MB/s eta 0:00:14\n",
      "     ------------------------ --------------- 39.3/63.9 MB 1.9 MB/s eta 0:00:13\n",
      "     ------------------------- -------------- 40.1/63.9 MB 1.9 MB/s eta 0:00:13\n",
      "     ------------------------- -------------- 40.9/63.9 MB 2.0 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 41.2/63.9 MB 2.0 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 41.7/63.9 MB 2.0 MB/s eta 0:00:12\n",
      "     -------------------------- ------------- 42.5/63.9 MB 2.0 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 43.3/63.9 MB 2.0 MB/s eta 0:00:11\n",
      "     --------------------------- ------------ 44.0/63.9 MB 2.0 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 44.8/63.9 MB 2.0 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 45.4/63.9 MB 2.0 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 46.1/63.9 MB 2.1 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 46.7/63.9 MB 2.1 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 47.4/63.9 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 48.2/63.9 MB 2.1 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 49.3/63.9 MB 2.1 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 50.1/63.9 MB 2.1 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 50.9/63.9 MB 2.1 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 51.6/63.9 MB 2.2 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 52.4/63.9 MB 2.2 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 53.2/63.9 MB 2.2 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 53.7/63.9 MB 2.2 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 54.3/63.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 54.8/63.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 55.1/63.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 55.6/63.9 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 56.1/63.9 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 56.6/63.9 MB 2.2 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 57.1/63.9 MB 2.2 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 57.7/63.9 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 58.2/63.9 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 58.5/63.9 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 59.0/63.9 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 59.5/63.9 MB 2.2 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 60.0/63.9 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 60.8/63.9 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 61.3/63.9 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 61.9/63.9 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  62.7/63.9 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  63.4/63.9 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  63.7/63.9 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 63.9/63.9 MB 2.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-cpp-python) (2.1.2)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from llama-cpp-python) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.1)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'error'\n",
      "Failed to build llama-cpp-python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for llama-cpp-python (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [20 lines of output]\n",
      "      \u001b[32m*** \u001b[1mscikit-build-core 0.10.7\u001b[0m using \u001b[34mCMake 3.30.5\u001b[39m\u001b[0m \u001b[31m(wheel)\u001b[0m\n",
      "      \u001b[32m***\u001b[0m \u001b[1mConfiguring CMake...\u001b[0m\n",
      "      2024-11-09 01:09:50,758 - scikit_build_core - WARNING - Can't find a Python library, got libdir=None, ldlibrary=None, multiarch=None, masd=None\n",
      "      loading initial cache file C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmp8_zarpsy\\build\\CMakeInit.txt\n",
      "      -- Building for: NMake Makefiles\n",
      "      CMake Error at CMakeLists.txt:3 (project):\n",
      "        Running\n",
      "      \n",
      "         'nmake' '-?'\n",
      "      \n",
      "        failed with:\n",
      "      \n",
      "         no such file or directory\n",
      "      \n",
      "      \n",
      "      CMake Error: CMAKE_C_COMPILER not set, after EnableLanguage\n",
      "      CMake Error: CMAKE_CXX_COMPILER not set, after EnableLanguage\n",
      "      -- Configuring incomplete, errors occurred!\n",
      "      \u001b[31m\n",
      "      \u001b[1m***\u001b[0m \u001b[31mCMake configuration failed\u001b[0m\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for llama-cpp-python\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (llama-cpp-python)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-cpp-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
